<!-- META
{"title":"Deep Reinforcement Learning, a textbook: Tabular Value-Based Reinforcement Learning","link":"https://arxiv.org/pdf/2201.02135","media":"book","tags":["rl"],"short":{"en":"classic reinforcement learning explanation","ja":"古典的な強化学習の説明"},"importance":5,"hasPage":true,"createdAt":1725599327.321,"updatedAt":1725599327.321}
META -->

## What to have
- agent, environment
- Markov decision process
- transition function, solution methods

## Marcov decision process
### Marcov property
next state determined only by the **current** state

### Formalism
5-tuple
(S, A, T_a, R_a, g)
- S: set of states
- A: set of actions
- T_a: probability of action **a** takes to next state when t -> t+1
- R_a: reward received when **s** -> **s'** by action **a**
- g: [0, 1], discount factor

### State
- for game: all pixels is a single state
- deterministic / stochastic
  - deterministic: all action leads to single state
  - stochastic: state led by action has probability
