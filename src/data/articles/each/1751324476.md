<!-- META
{"title":"LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees","link":"https://arxiv.org/abs/2404.05134","media":"academic","tags":["llm","behaviortree"],"short":{"en":"Earned robotic adaptive tasks by a novel method based on LLMs and Behavior Trees (BTs).","ja":"大規模言語モデル（LLM）とビヘイビアツリー（BT）に基づく新しい手法により、ロボットの適応的なタスク実行を実現した論文"},"importance":2,"hasPage":true,"createdAt":1751324476.942,"updatedAt":1751324476.942}
META -->

# LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees
- Earned robotic adaptive tasks by a novel method based on LLMs and Behavior Trees (BTs).
- 大規模言語モデル（LLM）とビヘイビアツリー（BT）に基づく新しい手法により、ロボットの適応的なタスク実行を実現した論文

## 著者
- Haotian Zhou
- Yunhan Lin
- Longwu Yan
- Jihong Zhu
- Huasong Min

## 背景
### 研究の意義
大規模言語モデル（LLM）は、ロボットがユーザーの意図を理解し、タスクのワークフローを推論する上で強力な能力を示している。 しかし、タスク実行中に発生する外部からの妨害にロボットが対処することは、依然として未解決の課題である。 本論文は、LLMとビヘイビアツリー（BT）を組み合わせることで、外部からの妨害に対して頑健で、適応的にタスクを遂行できるロボットシステムを提案するものである。 

### 関連研究
- **LLMベースのロボットタスク手法**:
    - PaLM-E , RT-2 , ChatGPT for Robotics , SayCan , VoxPoser など、多くの研究が存在する。これらの手法は、言語指示や画像からロボットの行動を生成し、ある程度の妨害（例：掴んだ物体を落とす）には対処できる。 
    - しかし、障害物によって目標位置に物体を置けない場合など、タスクの再計画が必要となるような外部妨害には対応できない。 これは、実行時に新しいアクションをより高い優先度で動的に追加する能力がないためである。 
- **ビヘイビアツリー (BT) の合成**:
    - BTは、そのモジュール性と反応性の高さからロボット工学で広く利用されている。 BTの合成に関する研究では、リアルタイムで新しいアクションを高い優先度で追加することが可能であり、これによりロボットは外部妨害に対処できる。 
    - しかし、これらの従来手法では、タスクの目標を事前に定義しておく必要があるという制約があった。 本研究では、この初期BTの構築をLLMによって自動化する点で異なる。 

## 手法
### 概要
本論文で提案する手法「LLM-BT」は、以下の4つのモジュールで構成される。 
- **Recognition**: 3Dカメラからの点群データを用いて、リアルタイムにシーン内の物体情報を認識し、セマンティックマップを構築する。 
- **Reasoning**: ユーザーからの言語指示とセマンティックマップに基づき、ChatGPTを用いてタスクを達成するための記述的ステップを推論する。 
- **Parser**: BERTベースのLLMを用いて記述的ステップからキーワードを抽出し、タスクの目標を表す初期ビヘイビアツリー（BT）を構築する。 
- **BTs Update**: 構築された初期BTを実行し、環境の変化やタスクの失敗に応じて、BTを動的に拡張（新しいアクションを追加）することで、適応的なタスクを遂行する。 

### 前提条件
- アクションを実行するための基本的な動作（例：掴む、置く、移動する）と、それに対応する事前条件・事後条件が定義されたアクションテンプレートライブラリ（ATL）が手動で構築されている必要がある。 

### 詳細
- **Recognitionモジュール**:
    - 3Dカメラでシーンの点群データを取得する。 
    - 提案された3D物体認識アルゴリズム[21]を用い、物体のID、名前、色、形状、3D空間座標などの情報を特定する。 
    - 認識した物体情報を、拡張性や構造の明確さに優れるXML形式のセマンティックマップとして書き出す。 

- **Reasoningモジュール**:
    - 入力として、ユーザーからの言語指示とRecognitionモジュールが生成したセマンティックマップを受け取る。 
    - ChatGPTの推論能力を活用し、タスクを達成するための一連の記述的ステップ（例：「"object 1"を棚レベル2の"position 22"に移動する」）を生成する。 
    - ChatGPTの出力には説明文などの不要なテキストが含まれることがあるため、テキストフィルターを通して記述的ステップのみを抽出する。 

- **Parserモジュール**:
    - **キーワード抽出**:
        - Reasoningモジュールから得られた記述的ステップを、BERTベースのLLMに入力する。 
        - 事前に定義されたラベル（B-Action, B-Target, B-Destinationなど）を用いて、ステップ内の各単語（トークン）を分類し、キーワードとして抽出する。 
    - **キーワード解析と初期BT構築**:
        - 抽出されたキーワードを「if-else」構造で順次解釈する。 
        - 'B-Action'ラベルのキーワードは、アクションテンプレートライブラリ（ATL）から対応するアクションの事後条件を持つ「条件ノード」を生成するトリガーとなる。 
        - 'B-Target'（操作対象）や'B-Destination'（目的地）などのキーワードは、条件ノードのパラメータとして設定される。
        - 全てのキーワードを処理した後、生成された全ての条件ノードを一つの「シーケンスノード」の子として配置し、タスク全体の目標を表す初期BTを構築する。 

- **BTs Updateアルゴリズム**:
    - **プロセス概要**: `Expand`と`Insert`という2つの主要な関数で構成される。 BTの実行が失敗(Failure)した場合に、失敗の原因となった条件ノード $c_f$ を特定し、それを成功(Success)させるためのサブツリーを動的に生成・挿入する。 
    - **Expand関数**:
        - 失敗した条件ノード $c_f$ を事後条件として持つようなアクション $a$ をアクションテンプレートライブラリ（ATL）から探索する。 
        - 見つかったアクション $a$ と、その実行に必要となる事前条件 $Pre(a)$ からなるサブツリー $\mathcal{T}_{st}$ を構築する。 
        - 最終的に、元の失敗ノード $c_f$ と、生成したサブツリー $\mathcal{T}_{st}$ を子に持つ「フォールバックノード」を作成し、これを拡張サブツリー $\mathcal{T}_{exp}$ として返す。 これにより、「もし $c_f$ が偽なら、$\mathcal{T}_{st}$ を実行して $c_f$ を真にする」というロジックが実現される。
    - **Insert関数**:
        - Expand関数で生成されたサブツリー $\mathcal{T}_{exp}$ を、元のBTに挿入する。 
        - **競合がない場合**: 新しいアクションが既存のタスクフローと競合しない場合、失敗したノード $c_f$ を単純に $\mathcal{T}_{exp}$ で置き換える（Replace）。 
        - **競合がある場合**: 新しいアクション（例：障害物をどかす）が既存のタスク（例：物体を置く）の前提条件と競合する場合、$\mathcal{T}_{exp}$ を競合するノードよりも高い優先度を持つ位置に追加（Add）する。 

### 評価方法
2種類のシミュレーション環境で実験を行った。 
- **貨物仕分け (Cargo sorting)**: 固定されたマニピュレータが、ユーザーの要求に応じて貨物を仕分けるタスク。 
- **家事サービス (Household service)**: 移動マニピュレーションロボットが、ユーザーが必要とする物を取ってくるタスク。 

両実験において、以下の条件で評価した。
- 5つの異なるケースを設定し、各ケースで20人の非専門家ユーザーがロボットに口頭で指示を与える。 
- ロボットが作業するたびに、ランダムな外部妨害（例：物体の落下、障害物による妨害）を発生させる。 
- 成功は、Reasoning、Parser、BTs Updateの各モジュールがそれぞれ正しく機能した場合にカウントされる。 
- アクションの成功率や3D認識の精度そのものは、本手法の評価と切り分けるため、100%成功すると仮定している。 

## 結果
### 概要
実験の結果、提案手法LLM-BTは、外部からの妨害がある状況でも、タスクを適応的に達成できることが実証された。 全体として、貨物仕分けタスクでは約85%、より複雑な家事サービスでは約75%の成功率を達成した。 

### 詳細
- **貨物仕分け実験**:
    - 全100試行（5ケース×20人）中、全体のタスク成功率は約85%であった。 
    - 失敗の主な原因は、ユーザーの要求が不明確だったことによるReasoningモジュールの推論ミス（10件）だった。 その他、Parserモジュールが未知のキーワードに対応できなかったケース（1件）、BTs Updateが解決不可能な妨害に直面したケース（1件）があった。 
    - 成功例では、ロボットは落下した物体を拾い直したり（再把持）、目的の動作を妨げる障害物を自ら移動させたりすることができた。 

- **家事サービス実験**:
    - 全体的な成功率は約75%に低下した。 
    - 環境が複雑になったことで、ユーザーの不明確な表現がReasoningの失敗につながる確率が高まった（16件）。 
    - また、複雑な環境は多様な記述的ステップを生成し、Parserモジュールのキーワード抽出データセットが対応できずに失敗するケースも見られた（6件）。 
    - 成功例では、ミルクの前に置かれた障害物をまず取り除き、その後にミルクを掴んでユーザーの元へ運ぶといった適応的な行動が確認された。 

## 先行研究との差分
### 手法面
- 既存のLLMベース手法が固定的な制御文やアクションリストを出力するのに対し、LLM-BTは環境変化に応じて新しいアクションを動的に追加・実行できる「可変的なビヘイビアツリー」を出力する。 
- 既存のBT合成手法ではタスク目標の事前定義が必要だったが、LLM-BTはLLMを用いることで、ユーザーの指示からタスク目標を含む初期BTを自動で構築する。 

### 結果面
- 既存手法では対応が困難であった、障害物の除去などタスクの再計画を必要とする外部妨害に対し、本手法は適応的に対処できることを実験で示した。 例えば、物体を置く動作が障害物によって妨げられた際に、障害物をどけるという新しいアクションを生成・実行し、タスクを継続することが可能である。 

## 議論
- **利点 (Advantages)**:
    - 本手法の最も顕著な利点は、その **適応性（Adaptability）** である。 環境の変化に応じて、アクションテンプレートライブラリ（ATL）から新しいアクションを追加し、それらに適切な実行優先度を割り当てることで、予期せぬ事態に対応できる。 

- **限界 (Limitations)**:
    - **シーン理解の弱さ**: システムはセマンティックマップから新しい知識（例：物体の相対的な位置関係）を学習することができない。 そのため、例えば「オブジェクトを特定の順序で整然と並べる」といった、より高度な空間推論を要する指示には対応できない。 
    - **手動でのATL構築**: 手法の核となるアクションテンプレートライブラリ（ATL）は、専門家やエンジニアが手動で作成・追加する必要がある。 システムに新しい種類のアクションを追加したい場合は、常に対応するテンプレートをATLに手動で定義しなければならない。 