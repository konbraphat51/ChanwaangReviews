<!-- META
{"title":"Single-shot Embedding Dimension Search in Recommender System","link":"https://arxiv.org/pdf/2204.03281","media":"academic","tags":["recommender"],"short":{"en":"reducing dimentions for large data in WeChat","ja":"WeChatの高次元削減"},"importance":1,"hasPage":true,"createdAt":1745881425.357,"updatedAt":1745881425.357}
META -->

## 「Single-shot Embedding Dimension Search in Recommender System」の詳細な日本語要約

**概要**

本論文は、深層推薦システムにおける特徴フィールドごとの最適な埋め込み（embedding）次元数の自動割り当て問題に取り組んでいます。従来は全特徴に同じ次元数を割り当てるのが一般的でしたが、これはメモリ・計算コストの増大や性能劣化につながることがあります。著者らは、SSEDS（Single-Shot Embedding Dimension Search）という手法を提案し、単一回のプルーニング操作で各特徴フィールドに異なる次元数を効率的に割り当て、精度を維持または向上させつつモデルの軽量化を実現します。

---

## 手法

**課題設定**

- 特徴ベースの推薦システムでは、高次元かつ疎な特徴を低次元の密なベクトル（埋め込み）に変換します。
- Embedding Dimension Search（EDS）問題とは、パラメータ予算$$\kappa$$のもと、各特徴フィールドに最適な埋め込み次元数を割り当てて損失関数を最小化しつつ、パラメータ数を削減することです。

**SSEDSの全体像**

SSEDSは以下の3段階で構成されます：

1. **事前学習（Pretraining）**
   - まず、全フィールドに同じ大きな次元数の埋め込みを割り当てたベースモデル（例：FM、DeepFM、Wide&Deep）を標準的な方法で事前学習します。
   - 埋め込みテーブルとモデルパラメータを最適化します。

2. **単一回プルーニング（Single-Shot Pruning）**
   - 各フィールド・各次元ごとに、その次元が損失関数に与える影響度（saliency score）を計算します。
   - この影響度は、補助的なインジケータ変数に対する損失の勾配を用いて、1回の順伝播・逆伝播で効率的に近似計算します。
   - 影響度に基づき次元を降順でランク付けし、パラメータ予算を満たすまで低スコアの次元を削除します。
   - これにより、各フィールドごとに異なる次元数を持つ「混合次元埋め込み」が得られます。

3. **再学習（Retraining）**
   - 特徴間の相互作用（例：内積）には同次元の埋め込みが必要なため、各フィールドごとに線形変換行列を導入して次元を揃えます（最大次元に合わせる）。
   - プルーニング後のスリムなモデルを再学習します。埋め込みは事前学習モデルから初期化し（Lottery Ticket仮説を活用）、変換行列や他のパラメータはランダム初期化します。

**アルゴリズム詳細**

- 影響度スコアは、損失関数の補助インジケータ変数に関する勾配の絶対値を正規化したものです。
- プルーニングはフィールド単位で行い、特徴単位では行いません（データの疎性やロングテール分布のため）。
- モデル非依存で、さまざまな推薦モデルに適用可能です。

---

## 実験結果

**オフライン実験**

- **データセット**：Criteo（4,600万件、39フィールド、100万特徴）、Avazu（4,000万件、22フィールド、60万特徴）
- **比較手法**：一様次元割り当てモデル（FM, DeepFM, Wide&Deep）、ヒューリスティックEDS（MDE）、ハイパーパラメータ最適化EDS（AutoDim）、埋め込みプルーニングEDS（PEP, Deeplight）
- **評価指標**：AUC（ROC曲線下面積）、モデルパラメータ数
- **主な結果**：
  - SSEDSは、90%の埋め込みパラメータを削減してもAUCを維持または向上させ、他手法よりも高精度を示しました。
  - 例：DeepFM＋SSEDSは、CriteoでAUC 1.7%向上、Avazuで4.3%向上しつつ、パラメータ90%削減を達成。
  - 埋め込みプルーニング型EDS（PEP, Deeplight, SSEDS）は、ヒューリスティックやHPO型よりも優れた性能。
  - SSEDSは単一回のプルーニングで済むため、学習効率が高く、推論も高速化。

**オンラインA/Bテスト**

- **実運用**：WeChat公式アカウントの推薦システムにSSEDSを導入し、数億ユーザーを対象に7日間のA/Bテストを実施。
- **結果**：
  - CTR（クリック率）が4%向上し、埋め込みパラメータを約90%削減。
  - 時間経過とともに改善傾向が強まり、動的なデータ分布にも適応。

**アブレーションスタディ**

- **再学習の有無**：プルーニング後に再学習しない場合でもSSEDSはベースモデルを上回るが、再学習ありの方が高精度。
- **Winning Ticket仮説**：再学習時に事前学習済みの埋め込みで初期化すると、ランダム初期化よりも良好な結果。
- **結論**：再学習＋Winning Ticket初期化のSSEDSが最良のAUCを達成。

**プルーニング分析**

- 影響度スコアはパワーロー分布に従い、ごく一部の次元が高い重要性を持つため、積極的なプルーニングが合理的。
- 大きな次元数が残るフィールドは少数で、多くのフィールドは小さな次元数またはゼロに割り当てられ、SSEDSが自動特徴選択機能も持つことを示唆。

---

## 結論

SSEDSは、推薦システムの埋め込み次元数自動探索において効率的かつ高精度な手法です。影響度スコアに基づく単一回のプルーニングで、各フィールドに最適な混合次元を割り当て、大幅なモデル軽量化と計算コスト削減を実現しつつ、精度も維持・向上します。オフライン・オンライン両面での大規模検証により、産業応用にも十分な有効性・実用性が示されました。SSEDSは自動特徴選択や動的データ分布への適応も可能であり、今後の推薦システム設計に大きな貢献が期待されます。

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/1274205/b7aff6c4-ad09-4b16-bfba-bdce0ffde654/2204.03281v2.pdf

---
Perplexity の Eliot より: pplx.ai/share