<!-- META
{"title":"EXAMINING THE ALIGNMENT OF LARGE LANGUAGE MODELS THROUGH REPRESENTATIVE HEURISTICS: THE CASE OF POLITICAL STEREOTYPES","link":"https://arxiv.org/pdf/2501.14294","media":"academic","tags":["llm","heuristics"],"short":{"en":"Earned knowledge about LLMs' political stereotyping by applying the framework of representative heuristics","ja":"代表性ヒューリスティックの枠組みを適用し、LLMの政治的ステレオタイプが人間より強くなる知見を得た論文"},"importance":2,"hasPage":true,"createdAt":1752865624.789,"updatedAt":1752865624.789}
META -->

# EXAMINING THE ALIGNMENT OF LARGE LANGUAGE MODELS THROUGH REPRESENTATIVE HEURISTICS: THE CASE OF POLITICAL STEREOTYPES
- Earned knowledge about LLMs' political stereotyping by applying the framework of representative heuristics
- 代表性ヒューリスティックの枠組みを適用し、LLMの政治的ステレオタイプに関する知見を得た論文

## 著者
- Jana Diesner [5]
- Sullam Jeoung [6]
- Yubin Ge [6]
- Haohan Wang [6]

## 概要
大規模言語モデル（LLM）が人間の価値観とどの程度一致しているか（アラインメント）を調査することは、特にLLMが意図通りに動作しない場合に重要性が増している。 [11] 本研究は、政治という領域におけるLLMと人間の価値観とのアラインメントを検証する。先行研究ではLLMの出力に政治的傾向が含まれることは示されてきたが、LLMが経験的な立場からどの程度、どのような条件下で逸脱するのかは十分に解明されていなかった。 [13, 14] このギャップを埋めるため、本研究では認知科学における**代表性ヒューリスティック**、すなわち人間が特定の集団の代表的な属性に過度に依存し、結果として誇張された信念を抱いてしまう現象に着目する。 [16] このレンズを通して、LLMがどのように政党に関する予測を誇張し、ステレオタイプを生み出すのかを実験的に検証した。 [17] 実験の結果、LLMは特定の政党の立場を模倣する能力を持つ一方で、人間の調査回答者以上にその立場を誇張する傾向があることが明らかになった。 [18] さらに、LLMは人間よりも代表性を過度に強調する傾向があり、これがLLMを政治的ステレオタイプに対して脆弱にしている可能性を示唆している。 [19, 20] また、人間において代表性ヒューリスティックを緩和することが知られているプロンプトベースの戦略をテストし、それらがLLMにおいても同様に有効であることを確認した。 [21]

## 背景
### 研究の意義
大規模言語モデル（LLM）が我々の私生活、職業、社会の多くの側面に影響を及ぼすにつれて、その出力が人間の意図や価値観とどのように比較され、あるいは科学的に「アラインメント」されているかを知ることへの関心が高まっている。 [23] この文脈において、LLMの潜在的な政治的傾向を理解することは、LLMの安全性にとって重要である。 [24] LLMは、その訓練データに存在する時間的、地理的、社会文化的な文脈を反映した経験的パターンを学習し、再現するため、データセットのバイアスに起因するステレオタイプを持つ可能性がある。 [41, 42]

### 関連研究
これまでの研究で、LLMが左翼的傾向や環境保護主義的なスタンスなど、政治的な偏りを示すことが確認されている。 [25] また、米国の共和党や民主党といった特定の政党に属するように条件づけられると、LLMはそれに対応する道徳的立場や様々な政治的争点に関するスタンスを模倣できることも示されている。 [26] しかし、これらの研究はLLMの政治的傾向を明らかにしたものの、LLMが経験的な（実際の人々の）立場からどの程度、どのような条件下で逸脱（例えば、誇張したり、過小評価したり）するのかという点は未解明のままであった。 [27]

本研究は、この知識のギャップを埋めるために、認知科学の知見を活用する。特に、人々が意思決定において対象集団の代表的な属性を過大評価する傾向である**代表性ヒューリスティック**に着目する。 [28] このヒューリスティックは、特定の事柄に対する人々の信念の誇張につながることが知られている。 [33] 例えば、共和党員の代表的な属性として「裕福である」というイメージが誇張されることがあるが、これはアメリカの富裕層の大部分が共和党員であるという経験的事実に関連している。 [34] 本研究では、このような認知科学の枠組みを用いて、LLMが人間と同様に、特定の政党について誇張された応答を生成するメカニズムを検証する。 [35]

## 手法
### 概要
本研究は、以下の3つのステップで実験を行った。
- LLMが生成した政治に関する応答が、ステレオタイプは経験的な現実に根差しているとする**「カーネル・オブ・トゥルース（真実の核）」仮説**に従うかを検証する。 [37, 81]
- LLMの応答が、認知バイアスの一種である**代表性ヒューリスティック**の影響を受けているかを定量的に評価する。 [49, 81]
- 人間において代表性ヒューリスティックを緩和することが示されている認知科学の知見に基づき、プロンプトベースの介入戦略を考案し、LLMにおける政治的ステレオタイプの緩和に有効かをテストする。 [83]

### 前提条件
- 分析対象は、米国の**共和党（Republicans）**と**民主党（Democrats）**の2つの政党に限定される。 [109, 332]
- 人間の経験的な政治的立場を測定するためのデータとして、公開されている大規模なサーベイデータセットである**ANES (American National Election Survey)**と**MFQ (Moral Foundation Questionnaire)**を再利用する。 [47, 175, 180]

### 詳細
本研究では、LLMによる政治的ステレオタイプの生成を定量化するために、以下の指標を定義し、分析を行った。

- **経験的平均 (Empirical Mean) $\mathbb{E}(a|X)$**: 実際の共和党支持者または民主党支持者が、ある政治的トピックについて自分自身の立場をどう評価したかを示すサーベイデータの平均値。 [114] これは、「あなた自身を1から7のスケール上のどこに位置づけますか？」といった質問（Empirical Question）に対する回答から計算される。 [115]
- **予測平均 (Predicted Mean) $\mathbb{E}^{B}(a|X)$**: LLM（または比較対象の人間）が、共和党または民主党の立場をどのように予測したかを示す回答の平均値。 [119] これは、「共和党／民主党を1から7のスケール上のどこに位置づけますか？」といった質問（Prediction Question）に対する回答から計算される。 [120]
- **代表性 (Representativeness) $R[a]$**: ある属性（例：リッカート尺度の特定の点数）が、一方の政党（例：共和党）にとって、もう一方の政党（例：民主党）と比較してどれだけ「代表的」かを示す指標。これは、各政党におけるその属性の条件付き確率の比 $\frac{P(a|X^{+})}{P(a|X^{-})}$ で計算される。 [95, 111]
- **典型 (Exemplar) $a^{*}$**: ある政党にとって最も代表的な属性。統計的に最も確率が高い属性とは必ずしも一致しない。 [122, 126] 人々が統計的に稀だが非常に代表的な属性を過度に重視する際に、最も顕著なステレオタイプが現れることが知られている。 [128]
- **カーネル・オブ・トゥルースの検証**: 予測平均 $\mathbb{E}^{B}(a|X^{+})$ が、2つの政党の経験的平均 $\mathbb{E}(a|X^{+})$ と $\mathbb{E}(a|X^{-})$ の線形結合でモデル化できるかを検証する。以下の式で $\gamma > 0$ となる場合、予測は経験的現実の核（カーネル・オブ・トゥルース）を反映しつつ、両者の差を誇張していると解釈できる。 [136, 142]
$$\mathbb{E}^{B}(a|X^{+})=(1+\gamma)\cdot\mathbb{E}(a|X^{+})-\gamma\cdot\mathbb{E}(a|X^{-})$$
- **代表性ヒューリスティックの検証**: 予測平均が、経験的平均に代表性の度合いを考慮した項を加えることでモデル化できるかを検証する。以下の式で $\epsilon_{X^{+}} > 0$ となる場合、予測平均は代表性ヒューリスティックの影響を受け、代表的な属性の方向に歪んでいると解釈できる。 [150, 154]
$$\mathbb{E}^{B}(a|X^{+})=\mathbb{E}(a|X^{+})+\epsilon_{X^{+}}\cdot(P_{A^{(N)}}^{X^{+}}-1)$$

### 評価方法
人間において、自分がヒューリスティックに頼っていると認識すると判断を修正できるという認知科学の知見に基づき、LLMにおけるステレオタイプを緩和するための3つのプロンプトベース戦略を評価した。 [158, 159]
- **AWARENESS**: プロンプトの冒頭で、代表性ヒューリスティックとそのステレオタイプへの関連性について明示的に説明を加える。 [160]
- **FEEDBACK**: LLMに一度回答を生成させた後、AWARENESS戦略と同様の説明を提示し、「これを念頭に置いて、回答を修正してください」と指示し、自己修正を促す。 [163]
- **REASONING**: プロンプトの末尾に「あなたの回答の理由を教えてください」という一文を加え、モデルに推論プロセスを明示させる。 [166]
これらの戦略の効果は、ステレオタイプ化のリスクを定量化する指標 $\kappa$（代表性と条件付き確率の間の乖離を示す）を用いて評価された。$\kappa$の値が低いほど、緩和戦略が効果的であると判断される。 [288]

## 結果と結論
### 概要
実験結果から、LLMが生成する応答は**「真実の核（kernel-of-truth）」**を含み、特定の政治的トピックに関する異なる政党の立場をある程度近似できることが示された。 [73] しかし、人間による応答と比較すると、LLMは**より二極化した表現**を生成する傾向があり、実際の党派的な立場を増幅（amplification）または減衰（diminution）させることで代表性ヒューリスティックを示した。 [74] この体系的な歪みは、LLMが特定の政治的所属と伝統的に関連付けられる特徴を過度に強調する、**政治的ステレオタイプ**に対して脆弱であることを示唆している。 [75] また、注意深く設計されたプロンプトベースの介入によって、これらのヒューリスティックの使用を部分的に緩和できることも示された。 [76]

### 詳細
- **予測平均と経験的平均の比較**: ANESデータセットの分析では、テストしたすべてのLLMが、共和党の立場を過大評価し、民主党の立場を過小評価する傾向を一貫して示した（図2）。 [189, 190] この誇張の度合いは、人間が他者の立場を予測する際のバイアス（Human Pred Mean）よりも大きかった。 [267] つまり、LLMは人間以上に党派間の対立を強調する傾向がある（図4）。 [265] MFQ（道徳基盤）データセットでも同様の傾向が見られ、特に共和党が重視するとされる「結束基盤（Loyalty, Authority）」において、顕著な誇張が見られた（図3）。 [193, 198, 218]
- **カーネル・オブ・トゥルースの検証**: ほとんどのLLMにおいて、予測平均は経験的平均のパターンを反映していた（表1）。 [269, 272] 具体的には、共和党に関する予測は共和党の経験的平均と正の相関を、民主党の経験的平均とは負の相関を示した。 [272] これは、LLMが経験的な分布の「核」を捉えつつ、政党間の差異を増幅させていることを裏付けている。 [274]
- **代表性ヒューリスティックの検証**: ANESとMFQの両データセットにおいて、ほとんどのモデルで代表性ヒューリスティックの存在を示す正の$\epsilon$値が観測された（表2）。 [278, 283] これは、LLMの出力が、確率分布全体を考慮するのではなく、政党の「典型的」な（代表的な）属性に強く影響されていることを示している。 [281]
- **緩和戦略の効果**: ベースライン（緩和策なし）のプロンプトが、ステレオタイプのリスク指標である$\kappa$値が最も高くなることが一貫して確認された（表3）。 [290] 提案された3つの緩和戦略（AWARENESS, FEEDBACK, REASONING）は、いずれも$\kappa$値を低下させ、ステレオタイプを緩和する可能性を示した。 [292] ただし、最も効果的な戦略はタスクとモデルによって異なり、ANESではREASONING戦略が、MFQではFEEDBACK戦略が最も$\kappa$値を大きく減少させた。 [291]

## 先行研究との差分
### 手法面
- LLMにおけるステレオタイプを分析するにあたり、これまでの研究で探求されてこなかった**「代表性ヒューリスティック」という認知科学の理論的枠組みを初めて導入**し、その分析手法を定式化した点。 [80, 313]
- これまでの研究が政治コンパス試験やモデルの操作可能性評価といった手法を用いていたのに対し、本研究は認知科学の理論を用いて、LLMが党派的な視点に同調する**根底にあるメカニズム**を解明しようと試みた点。 [307]

### 結果面
- LLMが単に政治的傾向を示すだけでなく、**人間による予測よりも強く党派間の立場を誇張し、二極化させる傾向がある**ことを定量的に明らかにした点。 [74]
- RLHF（人間からのフィードバックによる強化学習）のようなアラインメント手法が、意図せずして**特定の政治的信念に関する誇張を悪化させる可能性**を予備的に示した点。 [614]

## 議論
- **LLMにおける政治的代表性ヒューリスティックの下流タスクへの影響**: 予備的な調査として、代表性ヒューリスティックが偽情報検出タスクに与える影響を検証した。 [315] その結果、プロンプトに政党情報を含めることが必ずしもモデルの精度向上には繋がらない一方で、提示された政党によって精度にばらつきが生じることが示唆された。 [318, 603] これは、モデルに埋め込まれたヒューリスティックが、応用タスクの性能に意図しない影響を与える可能性を示している。
- **アラインメント手法はLLMの代表性ヒューリスティックに影響を与えるか？**: 近年、LLMを人間の価値観に沿わせるためのアラインメント手法（例：RLHF）が開発されている。 [319] 本研究では、RLHFで訓練されたLlama2-70bとそのベースモデルを比較する予備調査を行った。 [611] その結果、アラインメント済みのモデルの方が、特定の政治的立場（共和党）について、より誇張した回答を生成する傾向が見られた。 [613] これは、現在のアラインメント手法が、有害性の低減や有用性の向上には寄与する一方で、ステレオタイプの観点からは、かえって特定の信念の誇張を助長してしまう可能性があることを示唆している。 [614]