<!-- META
{"title":"Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions","link":"https://arxiv.org/abs/2405.07474","media":"academic","tags":["behaviortree","llm","ai"],"short":{"en":"Earned optimal and reliable Behavior Tree (BT) generation from human instructions by a two-stage framework that integrates Large Language Models (LLMs) for intent understanding and the Optimal Behavior Tree Expansion Algorithm (OBTEA) for behavior planning.","ja":"LLMによる意図理解と最適ビヘイビアツリー拡張アルゴリズム(OBTEA)による行動計画を統合した2段階のフレームワークにより、人間の自然言語指示から最適かつ信頼性の高いビヘイビアツリーの生成を実現した論文。"},"importance":4,"hasPage":true,"createdAt":1751326706.111,"updatedAt":1751326706.111}
META -->

# Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions
- Earned optimal and reliable Behavior Tree (BT) generation from human instructions by a two-stage framework that integrates Large Language Models (LLMs) for intent understanding and the Optimal Behavior Tree Expansion Algorithm (OBTEA) for behavior planning. 
- LLMによる意図理解と最適ビヘイビアツリー拡張アルゴリズム(OBTEA)による行動計画を統合した2段階のフレームワークにより、人間の自然言語指示から最適かつ信頼性の高いビヘイビアツリーの生成を実現した論文。 

## 著者
* Xinglin Chen 
* Yishuai Cai 
* Yunxin Mao 
* Minglong Li 
* Wenjing Yang 
* Weixia Xu 
* Ji Wang 

## 背景
### 研究の意義
家庭や産業環境など、実世界でロボットが人間の指示に従ってタスクを実行するためには、**適応性**と**信頼性**が不可欠です。 ビヘイビアツリー（BT）は、そのモジュール性（部品化のしやすさ）と反応性（環境変化への対応力）から、このようなシナリオにおけるロボットの制御アーキテクチャとして非常に適しているとされています。 しかし、既存のBT自動生成手法には、自然言語の指示を解釈する機能がなかったり、生成されたBTのタスク成功を理論的に保証できなかったりするという課題がありました。 近年、大規模言語モデル（LLM）を用いて直接BTを生成する試みもありますが、これは大量の「指示とBTのペア」データセットによるファインチューニングを必要とし、さらに生成されたBTの理論的な正当性や最適性を保証することができません。 

### 関連研究
BTの自動生成に関する研究は、進化的計算、強化学習、形式手法を用いた合成など、様々なアプローチで行われてきました。 中でも**BT Expansionアルゴリズム**は、行動計画を通じてBTを構築する手法であり、生成されたBTがタスクを成功裏に完了できることを理論的に保証する「健全」かつ「完全」なアルゴリズムとして知られています。 しかし、この手法を含む多くの既存研究は、あらかじめ形式化されたゴール条件（例：「`On(Coffee, Table)`」）を入力としており、人間が日常的に使うような曖昧な自然言語の指示から直接BTを生成することは困難でした。 一方で、LLMはタスク計画の生成に応用され始めていますが 、これをBT生成に直接利用するアプローチでは、前述の通り理論的な保証に欠けるという問題が残っていました。 

## 手法
### 概要
本研究では、人間の自然言語指示から効率的かつ信頼性の高いBTを生成するための、以下の2段階からなるフレームワークを提案しています。 

* **ステージ1：意図理解 (Intent Understanding)**
    * LLMの強力な言語理解能力を活用し、ユーザーからの自然言語指示を解釈します。 
    * 解釈されたタスクの目標は、一階述語論理における**整形式論理式 (Well-Formed Formula, WFF)** という厳密な形式で表現されます。 例えば、「テーブルをきれいにして、コーヒーか紅茶をください」という指示は、`¬Dirty(Table) ∧ (On(Coffee, Table) ∨ On(Tea, Table))` のように変換されます。 

* **ステージ2：最適行動計画 (Optimal Behavior Planning)**
    * 本研究で新たに提案する**最適ビヘイビアツリー拡張アルゴリズム (Optimal Behavior Tree Expansion Algorithm, OBTEA)** を用います。 
    * ステージ1で得られたWFF形式の目標を達成するために、最小のコストで実行可能であり、かつタスクの成功を理論的に保証する最適なBTを構築します。 

### 前提条件
本手法を適用するためには、以下の条件が事前に定義されている必要があります。
* 環境内に存在するオブジェクトの集合（例：コーヒー、テーブル）。 
* 環境の状態を表すための条件述語の集合（例：`On(object, place)`、`Dirty(object)`）。 
* ロボットが実行可能な行動を表すための行動述語の集合（例：`Clean(object)`、`PutDown(object, place)`）。 
* 各行動について、その実行条件（precondition）、実行による追加効果（add effects）、削除効果（delete effects）が定義されていること。 
* 各条件述語の真偽を判定するための条件ノードと、各行動述語を実行するための行動ノードがBTシステム内に実装されていること。 

### 詳細
#### ステージ1：意図理解
LLMに特化したデータセットでのファインチューニングを行うことなく、高精度な意図理解を実現するために、以下の3つの手法を導入しています。 

* **プロンプトエンジニアリング**: LLMへの入力（プロンプト）を工夫することで、LLMがタスクの文脈を理解し、正しい形式でゴールを出力できるように誘導します。 プロンプトには以下の4つの要素を含みます。
    1.  **オブジェクト**: 環境内に存在するオブジェクトのリスト。 
    2.  **条件述語**: ロボットが利用可能な条件述語のリスト。 
    3.  **Few-shotデモンストレーション**: 指示と、それに対応する正しいゴール（WFF）のペアを数例提示します。これにより、LLMはタスクの意図をより正確に学習します。 
    4.  **システム**: LLMに対する役割設定や、出力形式に関する指示を与えます。 

* **反射的フィードバック (Reflective Feedback)**: LLMの出力が文法的に誤っていたり、定義されていない述語やオブジェクトを含んでいたりした場合に、自動で修正を促す仕組みです。 
    1.  LLMの出力を構文・意味チェッカーで検証します。 
    2.  エラーが検出された場合、そのエラー内容（例：「`Table$Clean`は不正な述語です」）をブラックリストとして追加プロンプトに含め、再度LLMに同じ指示を入力します。 
    3.  正しい出力が得られるか、最大試行回数に達するまでこのプロセスを繰り返します。 

* **目標の正規化**: 正しいWFFとして得られたゴールを、**選言標準形 (Disjunctive Normal Form, DNF)** に変換します。 DNFは `(A ∧ B) ∨ (C ∧ D)` のような形式で、これにより2つの利点が得られます。
    1.  **曖昧性の排除**: ゴールの論理構造が明確になり、評価が容易になります。 
    2.  **サブゴールの分離**: DNF内の各項（例：`A ∧ B`）は、独立したサブゴールと見なすことができます。これらのサブゴールのいずれか1つを達成すれば、最終的な目標が達成されたことになります。これにより、後の行動計画がモジュール化され、扱いやすくなります。 

#### ステージ2：最適行動計画 (OBTEA)
OBTEAは、DNF形式で与えられたゴールを達成するための最適なBTを、**探索、拡張、圧縮、組立**の4つのステップで構築します (アルゴリズム1参照)。 

1.  **探索 (Exploration)**:
    * ダイクストラ法のようなアルゴリズムを用いて、ゴール状態から逆算し、初期状態に至るまでの最小コスト経路を探します。 
    * 各サブゴール $g_i$ を始点とし、そこから「どの行動（action）を実行すれば、この状態（condition）に至るか」を逆向きに探索していきます。 
    * 各状態までの最小コストを記録し、常に最もコストの低い経路を優先的に探索します。 

2.  **拡張 (Expansion)**:
    * 探索プロセスで見つかった「状態と行動のシーケンス」（例：「`c_a`という条件を満たした後、`a`という行動を実行する」）を、BTのサブツリーとして構築し、ルートノードであるフォールバックノードの子として追加していきます。 
    * この探索と拡張のプロセスは、現在の環境の初期状態で達成可能な条件が見つかるまで続けられます。 

3.  **圧縮 (Compaction)**:
    * 生成されたBTの実行時効率を高めるための最適化ステップです。 
    * BT内で隣り合ってチェックされる2つの条件（例：$c_1, c_3$）がある場合、それらの共通部分 $c' = c_1 \cap c_3$ を先にチェックするような構造に組み替えます。 
    * これにより、共通部分 $c'$ が偽であれば、残りの条件チェックをスキップでき、実行時のTick（評価）回数を削減できます。 

4.  **組立 (Assembly)**:
    * 全てのサブゴールに対して最適なサブツリーが生成された後、それらを最終的な一つのBTに統合します。 
    * 各サブツリーの達成に必要な総コストを計算し、コストが低い順にソートします。 
    * ソートされたサブツリーをフォールバックノードの下に配置することで、最も達成しやすい（低コストな）サブゴールから順に試行する、全体として最適なBTが完成します。 

### 評価方法
* **意図理解の評価**:
    * 独自に作成した100個の「指示と正解ゴールのペア」からなるデータセットを使用しました。 データセットは、ゴールの複雑さに応じて**Easy, Medium, Hard**の3つの難易度に分類されています。 
    * 評価指標として、LLMの出力が文法的に正しいかの割合を示す**文法正解率 (Grammatical Accuracy, GA)**と、出力が意味的に正解ゴールと等価であるかの割合を示す**解釈正解率 (Interpretation Accuracy, IA)**の2つを用いました。 

* **最適行動計画の評価**:
    * カフェシナリオのデータセットと、様々なスケール・複雑さを持つランダム生成テストセットの両方で評価を行いました。 
    * 評価指標は、生成されたBTの実行に要する**総コスト**と、BT実行中に条件ノードがチェックされる回数である**条件ノードTick数**です。 
    * ベースライン手法として、**BT Expansionアルゴリズム**と比較しました。 

## 結果
### 概要
実験の結果、提案フレームワークの有効性が示されました。
* LLM（GPT-3.5）は、Few-shotデモンストレーションと反射的フィードバックを用いることで、人間の指示の意図を理解し、WFF形式のゴールを高精度で生成できることが確認されました。 
* OBTEAは、ベースラインであるBT Expansionアルゴリズムと比較して、全てのテストケースにおいて、より低い総コストとより少ない条件ノードTick数を達成し、効率性と最適性の両方で優れていることが実証されました。 
* 最終的に、本フレームワークをシミュレータ上のカフェ環境に実装し、ロボットが顧客の複雑な指示に従って自律的にタスクを実行することに成功しました。 

### 詳細
* **意図理解の性能**:
    * GPT-3.5を用いた実験では、5つのデモンストレーションと5回のリトライ上限を設定した標準的な構成で、**Hard**レベルのタスクにおいても**GA 96.0%, IA 65.0%**という高い性能を達成しました。 
    * **アブレーション研究（要因分析）**:
        * デモンストレーションの数を0（Zero-shot）にすると、性能、特にIAが大幅に低下しました。 これは、LLMにとって論理文法を学ぶことよりも、自然言語の意図を解釈することの方が難しい課題であることを示唆しています。 
        * 反射的フィードバックを無効にすると、特にデモンストレーションがない場合にGAが著しく低下し、フィードバックの有効性が確認されました。 

* **最適行動計画の性能**:
    * カフェシナリオにおいて、OBTEAはベースラインと比較して、**総コストを約45%～55%削減**し、**条件ノードTick数をEasyレベルで78%、Hardレベルで44%削減**しました。 
    * ランダムテストセットにおいても、OBTEAは全てのケースでベースラインを上回り、最も複雑なケースでは**コストを50%以上、Tick数を約30%削減**するなど、その汎用性と優位性を示しました。 
    * **アブレーション研究（要因分析）**:
        * 圧縮（Compaction）ステップを無効にすると、Tick数が大幅に増加することが確認されました。 
        * 圧縮の再帰深度に関する分析では、深度をある程度（実験では4程度）増やすとTick数が急速に減少し、それ以上深くしても効果はほぼ飽和することがわかりました。これは、深すぎる再帰は不要で、効率的な最適化が可能であることを示しています。 

## 先行研究との差分
本研究の主要な比較対象は、**BT Expansionアルゴリズム** [Cai et al., 2021] です。 

### 手法面
* **最適性の追求**: BT Expansionはタスク成功を保証するBTを生成しますが、その実行コストが最適であることは保証しません。 一方、OBTEAはダイクストラ法に類似した探索により、**最小コストでタスクを達成する最適なBT**を生成することを目的としています。 
* **実行効率の向上**: OBTEAは、BTの実行時効率を高めるための**圧縮（Compaction）**ステップを導入しています。 
* **複雑なゴールの扱い**: OBTEAは、DNF形式で表現された複数のサブゴールを扱い、それらのコストに基づいて最適な実行順序を決定する**組立（Assembly）**ステップを持っています。これにより、より複雑で柔軟な指示に対応できます。 

### 結果面
* カフェシナリオとランダムテストセットの両方において、OBTEAによって生成されたBTは、BT Expansionによって生成されたBTよりも、**総コスト**と**条件ノードTick数**の両方で一貫して優れた値を示しました。 

## 議論
* 本研究は、LLMの直感的な意図理解能力と、記号論理（一階述語論理）に基づく厳密なプランニングを組み合わせたものであり、**ニューロシンボリックAI**のアプローチに沿ったものです。 これにより、適応性が高く、かつ信頼性のあるロボットエージェントの実現が期待されます。 
* カフェのウェイターロボットとしてのシミュレーション展開の成功は、本フレームワークが**実体化知能（Embodied Intelligence）**の分野において、実用的で有望なアプローチであることを示しています。 
* **今後の展望**:
    * RoboCup@Homeのようなより多様なベンチマークで、意図理解部分の性能をさらに評価・改善する。 
    * 最新のプランナーで用いられているようなヒューリスティクス（発見的手法）を導入し、OBTEAの計画効率をさらに向上させる。 
    * ロボットが自身の経験から環境のルール（例：「物を置くためには、まずその場所へ移動しなければならない」）を自動で学習するルール発見アルゴリズムを統合し、未知の環境への適応能力を高める。 