<!-- META
{"title":"LLM-as-BT-Planner: Leveraging LLMs for Behavior Tree Generation in Robot Task Planning","link":"https://arxiv.org/abs/2409.10444","media":"academic","tags":["llm","behaviortree","ai"],"short":{"en":"Earned by Enhanced Behavior Tree generation for robotic assembly by Leveraging Large Language Models (LLMs) with in-context learning and fine-tuning","ja":"大規模言語モデル(LLM)をコンテキスト内学習とファインチューニングで活用することにより、ロボット組立タスクにおけるビヘイビアツリー(BT)生成の能力向上を得た論文"},"importance":2,"hasPage":true,"createdAt":1751286279.49,"updatedAt":1751286279.49}
META -->

# LLM-as-BT-Planner: Leveraging LLMs for Behavior Tree Generation in Robot Task Planning
- Earned by Enhanced Behavior Tree generation for robotic assembly by Leveraging Large Language Models (LLMs) with in-context learning and fine-tuning
- 大規模言語モデル(LLM)をコンテキスト内学習とファインチューニングで活用することにより、ロボット組立タスクにおけるビヘイビアツリー(BT)生成の能力向上を得た論文

## 著者
- Jicong Ao
- Fan Wu
- Yansong Wu
- Abdalla Swikir
- Sami Haddadin

## 背景
### 研究の意義
[cite_start]ロボットによる組立タスクは、そのタスクのホライズンが長く、部品間の関係が複雑であるため、依然として解決が難しい課題とされています。 [cite: 9] [cite_start]このような複雑なタスクを計画・実行する手法として、ビヘイビアツリー（BT: Behavior Trees）がそのモジュール性と柔軟性から注目されていますが、手動での作成は多大な労力を要します。 [cite: 10] [cite_start]近年、大規模言語モデル（LLM）が行動シーケンスを生成する目的でロボットのタスクプランニングに応用され始めていますが、BT自体を生成する能力についてはまだ十分に調査されていませんでした。 [cite: 11] [cite_start]本研究は、このギャップを埋めるため、LLMをロボットの組立タスクプランニングにおけるBT生成に直接活用する新しいフレームワーク「LLM-as-BT-Planner」を提案するものです。 [cite: 12]

### 関連研究
- [cite_start]**古典的なプランニング手法**: Planning Domain Definition Language (PDDL) のような記号的 formalism に基づくアプローチは、状態空間内でゴールへの遷移パスを探索します。 [cite: 17, 20] [cite_start]しかし、タスクが大規模になると状態空間が指数関数的に増大するため、その応用には限界があります。 [cite: 47] [cite_start]また、ドメイン固有の知識に大きく依存し、生成された計画がオープンループであるという性質も、長期間のタスクプランニングにおける性能を低下させる一因となっています。 [cite: 48]
- [cite_start]**ロボティクスにおけるビヘイビアツリー (BT)**: BTは、状態非依存の階層的な木構造を持ち、モジュール性、再利用性、反応性に優れているため、有限状態機械（FSM）よりも複雑なタスクに適しているとされています。 [cite: 22, 23] [cite_start]BTの生成を自動化する研究として、記号的プランニング [cite: 25][cite_start]、模倣からの学習 [cite: 26][cite_start]、強化学習 [cite: 26] [cite_start]などがありますが、これらの手法もBTの基本構造や利用可能なサブツリーの手動設計に依然として大きく依存しています。 [cite: 27]
- [cite_start]**LLMベースのロボットタスクプランニング**: LLMの急速な進歩により、ロボットタスクプランニングへの応用研究が活発化しています。 [cite: 29] [cite_start]これまでの研究では、LLMは主に人間の指示をタスク仕様に変換したり [cite: 31, 32][cite_start]、世界の状況を追跡したり [cite: 57] [cite_start]するために利用されてきました。LLMを用いてBTを直接生成するフレームワークはまだ存在せず [cite: 32, 60][cite_start]、特にロボット組立タスクにおけるBT生成能力は包括的に調査されていませんでした。 [cite: 61]

## 手法
### 概要
[cite_start]本論文で提案されているフレームワーク「LLM-as-BT-Planner」は、3つのレベルで構成されています。 [cite: 7]
- [cite_start]**高レベル**: ユーザーからの自然言語による指示を、高レベルのLLMベース組立プランナーが受け取ります。 [cite: 67] [cite_start]プランナーは、タスク知識を基にタスクを分解し、一連のサブゴールシーケンスを生成します。 [cite: 67, 68]
- [cite_start]**中レベル**: 高レベルで生成されたサブゴールシーケンスを、LLMベースのBTジェネレーターがプランニングのターゲットとして受け取ります。 [cite: 69] [cite_start]ジェネレーターは、ロボットのアクション知識（PDDL風形式）、ワールドモデルからの世界状態（RDF風形式）、およびBTの定義を参照して、実行可能なBTを生成します。 [cite: 71, 72]
- [cite_start]**低レベル**: 生成されたBTはロボットインターフェースによってロードされ、ワールドモデルからの空間情報などを利用して実行されます。 [cite: 73] [cite_start]また、このプロセスには、シミュレーションによる事前検証や、人間からのフィードバックによる実行時の再計画機能も組み込まれています。 [cite: 74, 75]

### 前提条件
[cite_start]本研究におけるタスクプランニング問題は、以下の要素からなるタプル `(O, P, C, R, A, T, I, G, t)` として形式化されます。 [cite: 62]
- [cite_start]`O`: 環境内に存在するすべてのオブジェクトの集合。 [cite: 63]
- [cite_start]`P`: オブジェクトのプロパティ（例: `isEmpty`）。 [cite: 63, 122]
- [cite_start]`C`: オブジェクト間の制約（例: `canManipulate`）。アクションによって変化しません。 [cite: 64, 65, 123]
- [cite_start]`R`: オブジェクト間の関係（例: `isInsertedTo`）。アクションによって変化します。 [cite: 64, 65, 123]
- [cite_start]`A`: ロボットが実行可能なアクションの集合（例: `insert`, `pick_up`）。 [cite: 64, 125]
- [cite_start]`T`: 状態遷移モデル `S × A → S`。 [cite: 65]
- [cite_start]`I`, `G`: それぞれタスクの初期状態とゴール状態。 [cite: 65]
- [cite_start]`t`: ゴール状態 `G` に対応する、自然言語で与えられる高レベルのタスク記述。 [cite: 65]
- [cite_start]`O, P, C, R, A, I` は既知であると仮定されます。 [cite: 66]

### 詳細
[cite_start]本フレームワークでは、LLMを用いてBTを生成するために、4つの異なるコンテキスト内学習（In-context Learning）手法が設計・評価されました。 [cite: 78]

- **Scheme 1: One-step generation (ワンステップ生成)**
    - [cite_start]LLMが、与えられたサブゴール、初期状態、および関連知識から、単一のステップで完全なBTを直接生成する最も基本的な手法です。 [cite: 80, 81]
    - [cite_start]生成されたBTは直接実行され、失敗した場合は再計画のトリガーとなります。 [cite: 82, 83]
- **Scheme 2: Iterative generation (反復生成)**
    - [cite_start]ワンステップ生成で作成したBTを、まずシミュレーターで実行します。 [cite: 85, 86]
    - [cite_start]シミュレーションで構造的エラーなどの問題が検出された場合、その失敗理由をフィードバックとしてLLMに与え、BTを修正・再生成させます。 [cite: 87]
- **Scheme 3: Human-in-the-loop generation (人間参加型生成)**
    - [cite_start]まず、シーケンシャルプランナーがサブゴールを達成するための手順を自然言語で箇条書きにしたプランを生成し、これをBT生成のガイドとしてLLMに与えます。 [cite: 90]
    - [cite_start]BTが生成された後、人間がその内容を確認し、改善のためのフィードバックを自然言語で提供することができます。 [cite: 91] [cite_start]このフィードバックは実行後にも可能で、柔軟な計画修正を実現します。 [cite: 92]
- **Scheme 4: Recursive generation (再帰的生成)**
    - [cite_start]BT生成プロセスを「MakePlan（アクションシーケンス生成）」、「MakeTree（サブツリー生成）」、「PredictState（状態予測）」の3つのステップに分割します。 [cite: 94]
    - [cite_start]アルゴリズムに従ってこれらのステップを再帰的に呼び出すことで、BTを段階的に拡張・構築していきます。 [cite: 94] [cite_start]これにより、生成の精度と堅牢性の向上を目指しますが、リソース消費は増加します。 [cite: 99]

### 評価方法
- **実験設定**:
    - [cite_start]7自由度のFranka Emika Pandaロボットアームを用いた実機検証が行われました。 [cite: 111]
    - [cite_start]メインの評価タスクとして、Siemens Robot Assembly Challengeのギアセット組立（ギアベース、シャフト3本、ギア3個の組付け）が用いられました。 [cite: 117, 118]
    - [cite_start]加えて、Furniture Assembly Benchmarkの椅子とランプの組立タスクも評価に使用されました。 [cite: 126]
    - [cite_start]評価には、GPT-4、GPT-3.5、Mistral-7B、Llama2-13B-chatといった複数のLLMが使用されました。 [cite: 120, 127, 128]
- **ファインチューニング**:
    - [cite_start]オープンソースのLLMであるMistral-7BとLlama2-13B-chat、およびGPT-3.5を対象に、2種類のタスクでファインチューニングが行われました。 [cite: 127, 128]
        - [cite_start]**Unit-tree generation**: 1つのロボットアクションを、対応する前提条件とアクションノードを持つ単位BTに変換するタスク。 [cite: 102, 103]
        - [cite_start]**One-step generation**: 1つの組立目標（サブゴール）から、それを達成するための完全なBTを生成するタスク。 [cite: 105, 106]
    - [cite_start]学習データは、ギアセット組立タスクの実行ログから収集され、検証は椅子とランプの組立タスクのデータで行われました。 [cite: 129, 130, 133]
- **評価指標**:
    - [cite_start]**SR (Success Rate)**: 生成されたBTが実行可能で、論理的に一貫し、目標を達成できた割合。 [cite: 134]
    - [cite_start]**LC (Logical Coherence)**: BT内の実行順序が論理的に正しく、前提条件の違反がない割合。 [cite: 136]
    - [cite_start]**Exec (Executability)**: 生成されたBTが規定のフォーマットに準拠し、実行可能であった割合。 [cite: 138]
    - [cite_start]**GD (Generation Duration)**: BTの生成に要した時間。 [cite: 140]
    - [cite_start]**TC (Token Consumption)**: BTの生成に消費されたトークン数。 [cite: 141]

## 結果
### 概要
[cite_start]提案された4つのコンテキスト内学習手法の評価では、「人間参加型生成（Human-in-the-loop）」が最も高い成功率（SR）を達成しました。 [cite: 150] [cite_start]一方、LLMのファインチューニングは、モデルの構造化出力能力（Executability）を顕著に向上させましたが、複雑な推論を必要とするタスクの成功率（SR）や論理的一貫性（LC）への改善効果は限定的でした。 [cite: 43, 199]

### 詳細
- **コンテキスト内学習の結果**:
    - [cite_start]GPT-4を用いた評価では、全手法で高い実行可能性（Exec）が示されました。 [cite: 144]
    - [cite_start]**人間参加型生成**は、SR（16/17）とLC（16/17）の両方で最も優れた性能を示しました。これは、ユーザーからの具体的で的を射たフィードバックが、LLMの計画生成を効果的に導いたためです。 [cite: 159]
    - [cite_start]**ワンステップ生成**は、SRが12/17であり、失敗の主な原因は、必要なアクションが不足しているなど、生成されたツリーの深さが不十分なことでした。 [cite: 146]
    - [cite_start]**反復生成**は、ワンステップ生成と同等のSR（12/17）であり、シミュレーションからのフィードバックが汎用的すぎたため、性能向上には繋がりませんでした。 [cite: 156]
    - [cite_start]**再帰的生成**は、LCは最高（17/17）でしたが、Execは最も低く（13/17）、生成時間とトークン消費も最大となりました。 [cite: 164] [cite_start]これは、複数回の再帰的なLLM呼び出しが、生成の不安定性を増幅させたためと考えられます。 [cite: 149, 166]
- **ファインチューニングの結果**:
    - [cite_start]**事前学習済みモデルの比較**: GPT-4は、より小規模なモデル（GPT-3.5、Llama-13B、Mistral-7B）と比較して、特に複雑な「ワンステップ生成」タスクにおいて、すべての指標で圧倒的に優れた性能を示しました。 [cite: 167, 168]
    - **ファインチューニングの効果**:
        - [cite_start]ファインチューニングにより、小規模LLMの構造化出力能力（Exec）と、単純なタスクにおけるコンテキスト学習能力（Unit-treeタスクのLC）は大幅に向上しました。 [cite: 170, 171] [cite_start]例えば、ワンステップタスクにおけるMistral-7BのExecは0/10から8/10へ、Llama-13Bは5/10から9/10へと改善されました。 [cite: 170]
        - [cite_start]しかし、内部的な依存関係の推論を必要とする複雑な「ワンステップ生成」タスクでは、ファインチューニング後も小規模LLMのSRやLCは0/10や1/10と低いままでした。 [cite: 172, 178]
        - [cite_start]この結果は、ファインチューニングが小規模LLMの推論能力そのものを向上させるには限界があることを示唆しており、モデルのパラメータ数の少なさや学習データ不足が原因として考えられます。 [cite: 179, 180]
- **実機検証**:
    - [cite_start]提案手法によって生成されたBTを用いて、「gear1をshaft1に挿入する」というサブゴールを達成する一連の組立作業を、Franka Emikaロボットで成功裏に実行できることが実証されました。 [cite: 181, 186, 187]

## 先行研究との差分 
本研究は、LLMをBT生成に活用した初期の研究である `LLM-BT` [13] などを踏まえています。

### 手法面
- [cite_start]多くの先行研究では、LLMは人間の指示をタスク仕様に変換するなどの補助的な役割で使われていましたが、本フレームワークはLLMを用いて実行可能なBTを「直接」生成する点に新規性があります。 [cite: 4, 32, 60]
- [cite_start]4種類の異なるコンテキスト内学習手法（One-step, Iterative, Human-in-the-loop, Recursive）を提案し、それらを体系的に比較評価しています。 [cite: 40, 41]
- [cite_start]GPTシリーズだけでなく、オープンソースの小規模LLMに着目し、ファインチューニングによる性能向上を定量的に分析しています。 [cite: 14]

### 結果面
- [cite_start]本研究は、LLMのBT生成能力を包括的に調査・評価した最初の研究であると主張しています。 [cite: 61]
- 様々なLLM、手法、そしてファインチューニングの有無による性能の違いを、SR、LC、Execといった複数の指標を用いて詳細に比較し、それぞれの長所と短所を明らかにしました。

## 議論
本研究の限界として、以下の点が挙げられています。
- [cite_start]**リソース消費**: 「再帰的生成」手法は、論理的な一貫性を高く保てる一方で、計算リソース（時間とトークン）の消費が非常に激しく、実用化には改善が必要です。 [cite: 189]
- [cite_start]**ファインチューニングの限界**: ファインチューニングは、小規模LLMの構造化出力能力を改善しましたが、複雑なタスクにおける推論能力の向上には限定的な効果しかありませんでした。 [cite: 190] [cite_start]これは、モデルのパラメータ数が根本的に不足していることや、より多様で大規模な学習データが必要であることを示唆しています。 [cite: 191]
- [cite_start]**BTのスケーラビリティ**: タスクのステップ数が非常に多くなると、BTが深くネストし、ノード間で競合が発生する可能性があります。 [cite: 192, 193] [cite_start]本研究では高レベルでのタスク分解によりこの問題をある程度緩和していますが、より大規模なタスクへの適用性については更なる検討が必要です。 [cite: 194]