<!-- META
{"title":"Search Engines & Society -Information Quality and the Potential of AI","link":"https://www.u-tokyo.ac.jp/focus/en/events/z1701_00042.html","media":"netpage","tags":["google","lt","searchengine"],"short":{"en":"Speech from Dr. Prabhakar Raghavan Senior Vice President of Google","ja":"Dr. Prabhakar Raghavan Senior Vice President of Googleの発表"},"importance":1,"hasPage":true,"createdAt":1718795206.176,"updatedAt":1718795206.176}
META -->

## quality
### classic information retrieval
SRP: ranked list of documents

### measure quality
human judges assign Boolean relevance to query-doc pairs

25years ago, no spam docs
closed system

### state of web
#### 30 years ago
economic incentive to co-opt search engine ranking algorithm
* tobe found is to be in business
* span, keyword stuffing

### improvements
A/B experiments

* Ranking changes  
iterative improvement

* Feature improvements  
other than documents

--------

* directly answer the need behind the query

* consensus of traditionary authoritative sources

### How google divide whether a new idea is good to launch into production?
query has...
* navigational  
japan airlines
* direct answers  
tokyo tower height
* no one right answer  
best yellow dress
* compositional  
* transactional  
* local  
plumber, pizza -> nearby  
falafel -> at there

There is no unified answer.
Difficult to quantify what succeed

#### human eval
evaluator using extensive guidelines (170+ pages!!!!)

Evaluate treatment is better than the control.

Launches are driven by evaluator.
**should not be the employees' preferences**

### pushing user experience
* Elevate authoritative, relevant info  
Through ranking, direct answers, adjunct info

* Deprecate low quality info  
**not eliminating**

* rapidly changing results -> cannot get reliable source -> warn the user

### Clear deleared policy
* may be temporary violated
 * Use feed back to improve algorithm
* help users understand/evaluate their results
* policies should **ideally be public, robust and durable** 

### How do we handle the challenge of misinformation?
very hard

Factuality: algorithmic distillation of the consensus of traditionally authoritative resources
-> give large interface for answer

if don't have uniform answer...
-> show all, let it for users

**not choosing what is misinformation**

## "word wide" web
everyday have 15% brand new queries

webpages is not increasing thesedays

time spent on browser only 23 minutes
People seeing closed app

language
* 1st: Eng 55%
* 2nd: Spanish 5%

Arabic (0.7%)
Hindi(0.1%)
<- many speakers but less sources

### Cross language information retrieval
selected English docs are translated and indexed
-> searchable

translation errors can lose many subtleties

Sinple Eng Wikipedia ~ 250K
Pashto ~ 20K

## LLM and search engines
* language models
* multimodal embeddings
  * representing text images video in a common space
  * efficient retrival

LLM are prediction engines
not understanding

BERT -> "you shall know a word by the company it keeps"

Multimodality: better user intent expression
-> Google Lens, Circle to Search

AI overview
* google more used
* more satisfied

Pithy overview leading to detailed links
* users enjoy the fluidity
  * especially for longer q's like how-to's
* have more clicks

### limitations?
correlation != causation
LLM != sound reasoning, intelligence or sentience

Pareto Frontier: Fluidity vs Factuality
tradeoff

### feasibility: the final frontier
* users expect more than search
 * plan trip
 * fundamental algorithmic bottlenecks cannot be overcome with LLM
 * latency <- need improvement
















